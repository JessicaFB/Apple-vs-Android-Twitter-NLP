{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Step-1:-Load-the-Data/Filtering-for-Chosen-Zipcodes\" data-toc-modified-id=\"Step-1:-Load-the-Data/Filtering-for-Chosen-Zipcodes-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Step 1: Load the Data/Filtering for Chosen Zipcodes</a></span></li><li><span><a href=\"#Step-2:-Data-Preprocessing\" data-toc-modified-id=\"Step-2:-Data-Preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Step 2: Data Preprocessing</a></span></li><li><span><a href=\"#Step-3:-EDA-and-Visualization\" data-toc-modified-id=\"Step-3:-EDA-and-Visualization-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Step 3: EDA and Visualization</a></span></li><li><span><a href=\"#Step-4:-Reshape-from-Wide-to-Long-Format\" data-toc-modified-id=\"Step-4:-Reshape-from-Wide-to-Long-Format-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Step 4: Reshape from Wide to Long Format</a></span></li><li><span><a href=\"#Step-5:-SARIMAX-Modeling\" data-toc-modified-id=\"Step-5:-SARIMAX-Modeling-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Step 5: SARIMAX Modeling</a></span></li><li><span><a href=\"#Step-6:-Interpreting-Results\" data-toc-modified-id=\"Step-6:-Interpreting-Results-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Step 6: Interpreting Results</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load the Data/Filtering for Chosen Zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import itertools\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('up_to_date_zillow_data.csv')\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>RegionType</th>\n",
       "      <th>StateName</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>1996-01-31</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-10-31</th>\n",
       "      <th>2019-11-30</th>\n",
       "      <th>2019-12-31</th>\n",
       "      <th>2020-01-31</th>\n",
       "      <th>2020-02-29</th>\n",
       "      <th>2020-03-31</th>\n",
       "      <th>2020-04-30</th>\n",
       "      <th>2020-05-31</th>\n",
       "      <th>2020-06-30</th>\n",
       "      <th>2020-07-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>61639</td>\n",
       "      <td>0</td>\n",
       "      <td>10025</td>\n",
       "      <td>Zip</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York-Newark-Jersey City</td>\n",
       "      <td>New York County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1416272.0</td>\n",
       "      <td>1409421.0</td>\n",
       "      <td>1407017.0</td>\n",
       "      <td>1412042.0</td>\n",
       "      <td>1414135.0</td>\n",
       "      <td>1415095.0</td>\n",
       "      <td>1408966.0</td>\n",
       "      <td>1401018.0</td>\n",
       "      <td>1389676.0</td>\n",
       "      <td>1384859.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>84654</td>\n",
       "      <td>1</td>\n",
       "      <td>60657</td>\n",
       "      <td>Zip</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago-Naperville-Elgin</td>\n",
       "      <td>Cook County</td>\n",
       "      <td>358776.0</td>\n",
       "      <td>...</td>\n",
       "      <td>957541.0</td>\n",
       "      <td>956310.0</td>\n",
       "      <td>954994.0</td>\n",
       "      <td>954985.0</td>\n",
       "      <td>956480.0</td>\n",
       "      <td>958337.0</td>\n",
       "      <td>959091.0</td>\n",
       "      <td>958959.0</td>\n",
       "      <td>958378.0</td>\n",
       "      <td>959519.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>61637</td>\n",
       "      <td>2</td>\n",
       "      <td>10023</td>\n",
       "      <td>Zip</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York-Newark-Jersey City</td>\n",
       "      <td>New York County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1669612.0</td>\n",
       "      <td>1663472.0</td>\n",
       "      <td>1659302.0</td>\n",
       "      <td>1662263.0</td>\n",
       "      <td>1662774.0</td>\n",
       "      <td>1658055.0</td>\n",
       "      <td>1649411.0</td>\n",
       "      <td>1641047.0</td>\n",
       "      <td>1639442.0</td>\n",
       "      <td>1635311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>91982</td>\n",
       "      <td>3</td>\n",
       "      <td>77494</td>\n",
       "      <td>Zip</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>Katy</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land</td>\n",
       "      <td>Harris County</td>\n",
       "      <td>200271.0</td>\n",
       "      <td>...</td>\n",
       "      <td>335925.0</td>\n",
       "      <td>335929.0</td>\n",
       "      <td>336035.0</td>\n",
       "      <td>335760.0</td>\n",
       "      <td>335937.0</td>\n",
       "      <td>336360.0</td>\n",
       "      <td>337373.0</td>\n",
       "      <td>338225.0</td>\n",
       "      <td>338713.0</td>\n",
       "      <td>338889.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84616</td>\n",
       "      <td>4</td>\n",
       "      <td>60614</td>\n",
       "      <td>Zip</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago-Naperville-Elgin</td>\n",
       "      <td>Cook County</td>\n",
       "      <td>540023.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1187731.0</td>\n",
       "      <td>1185049.0</td>\n",
       "      <td>1183037.0</td>\n",
       "      <td>1182915.0</td>\n",
       "      <td>1185225.0</td>\n",
       "      <td>1187244.0</td>\n",
       "      <td>1188570.0</td>\n",
       "      <td>1188375.0</td>\n",
       "      <td>1189551.0</td>\n",
       "      <td>1192253.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RegionID  SizeRank  RegionName RegionType StateName State      City  \\\n",
       "0     61639         0       10025        Zip        NY    NY  New York   \n",
       "1     84654         1       60657        Zip        IL    IL   Chicago   \n",
       "2     61637         2       10023        Zip        NY    NY  New York   \n",
       "3     91982         3       77494        Zip        TX    TX      Katy   \n",
       "4     84616         4       60614        Zip        IL    IL   Chicago   \n",
       "\n",
       "                              Metro       CountyName  1996-01-31  ...  \\\n",
       "0       New York-Newark-Jersey City  New York County         NaN  ...   \n",
       "1          Chicago-Naperville-Elgin      Cook County    358776.0  ...   \n",
       "2       New York-Newark-Jersey City  New York County         NaN  ...   \n",
       "3  Houston-The Woodlands-Sugar Land    Harris County    200271.0  ...   \n",
       "4          Chicago-Naperville-Elgin      Cook County    540023.0  ...   \n",
       "\n",
       "   2019-10-31  2019-11-30  2019-12-31  2020-01-31  2020-02-29  2020-03-31  \\\n",
       "0   1416272.0   1409421.0   1407017.0   1412042.0   1414135.0   1415095.0   \n",
       "1    957541.0    956310.0    954994.0    954985.0    956480.0    958337.0   \n",
       "2   1669612.0   1663472.0   1659302.0   1662263.0   1662774.0   1658055.0   \n",
       "3    335925.0    335929.0    336035.0    335760.0    335937.0    336360.0   \n",
       "4   1187731.0   1185049.0   1183037.0   1182915.0   1185225.0   1187244.0   \n",
       "\n",
       "   2020-04-30  2020-05-31  2020-06-30  2020-07-31  \n",
       "0   1408966.0   1401018.0   1389676.0   1384859.0  \n",
       "1    959091.0    958959.0    958378.0    959519.0  \n",
       "2   1649411.0   1641047.0   1639442.0   1635311.0  \n",
       "3    337373.0    338225.0    338713.0    338889.0  \n",
       "4   1188570.0   1188375.0   1189551.0   1192253.0  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LA = df[df['City'] == 'Austin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LA.sort_values(by='SizeRank', na_position='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top two in size rank are the West Hollywood and Palms neighborhoods. This makes sense as these are known to be very affluent neighborhoods in the Greater Los Angeles area. A less than 4,000 square foot penthouse apartment at the Edition on Sunset Blvd. in West Hollywood was listed on Zillow at $18.9M in 2020. \n",
    "\n",
    "The third ranked zipcode is in a pretty poor neighborhood. This makes me wonder if it is mostly multifamily units being sold here, which would increase the median home sale price for this zipcode. \n",
    "\n",
    "Next on the list is the zipcode containing Silverlake and Echo Park, which are popular hipster neighborhoods where some celebritites live and home to some very beautiful and nice homes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just checked and it looks like 'RegionName' is the zipcode and 'RegionID' is extra information that we don't need. So I will go ahead and drop that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LA = df_LA.drop(['RegionID','SizeRank'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetimes(df):\n",
    "    return pd.to_datetime(df.columns.values[7:], format='%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_datetimes(df_LA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: EDA and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# font = {'family' : 'normal',\n",
    "#         'weight' : 'bold',\n",
    "#         'size'   : 22}\n",
    "\n",
    "# matplotlib.rc('font', **font)\n",
    "\n",
    "# # NOTE: if you visualizations are too cluttered to read, try calling 'plt.gcf().autofmt_xdate()'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Reshape from Wide to Long Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_data(df):\n",
    "    melted = pd.melt(df, id_vars=['RegionName', 'City', 'State', 'Metro', 'CountyName'], var_name='time')\n",
    "    melted['time'] = pd.to_datetime(melted['time'], infer_datetime_format=True)\n",
    "    melted = melted.dropna(subset=['value'])\n",
    "    return melted#.groupby('time').aggregate({'value':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LA_melt = melt_data(df_LA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LA_melt_sort = df_LA_melt.sort_values(by=['RegionName','time','value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LA_melt_sort['RegionName'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are 95 different zipcodes in our dataset for Los Angeles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_LA_melt_sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for those 95 zipcodes we have 24,761 datapoints. That's a good amount, giving an average of about 2,500 data points per zip code. Some may have more than others. We can explore that more when we come to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LA_melt_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcodes = df_LA_melt_sort['RegionName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "labels = []\n",
    "for zipcode in zipcodes:\n",
    "    df_zip = df_LA_melt_sort[df_LA_melt_sort['RegionName'] == zipcode]\n",
    "    plt.plot(df_zip['time'],df_zip['value'], label=zipcode)\n",
    "    labels.append(zipcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.lineplot(x='time', y='value', data=df_LA_melt_sort, hue='RegionName', palette=\"rainbow\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zipcodes**\n",
    "\n",
    "We can see a similar trend amongst all of our zipcodes. A few seem to be much higher than others, representing the more affluent neighborhoods. \n",
    "\n",
    "This data set represents median housing sale prices, so they could also include multifamily housing units as well, which would sell for a higher price than nearby single family homes. I imagine though overall the median would be representative and not skewed by this as density tends to be mixed (single family homes and multifamily homes), and sometimes in multifamily homes the individual apartments or condos are listed for sale individually. \n",
    "\n",
    "**Housing Bubble**\n",
    "\n",
    "We can see the housing bubble of 2008 in the data here. Home sale values start increasing rapidly in 2004, then max out late 2006/early 2007 and begin to dip to a min in around 2009. Some zipcodes slowly drop even lower for the next couple of years. Prices slowly begin to recover, reaching max bubble values in about 2013, 6 years after the bubble burst. \n",
    "\n",
    "Since the market is volatile and bubbles are somewhat unpredictable and do occur, with another one being anticipated in 2020-2022, I am going to leave this data in the data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: SARIMAX Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I conducted research and found that there is seasonality in home sales, so I am going to use SARIMA for my ARIMA Modeling, which integrates seasonality in the model. \n",
    "\n",
    "**Seasonality**\n",
    "\n",
    "According to the National Association of Realtors, the number of home sales increases significantly in the spring, with home sales increasing by 34% in February and March. \n",
    "\n",
    "Sales continue upward with the busiest home selling months being May through August, accounting for 40% of United States annual home sales volume. \n",
    "\n",
    "The slowest months are November through February, with January being the slowest. \n",
    "\n",
    "Prices of homes slightly increase during surge months when the demand in the market is higher. Therefore selling homes during these peak times could prove to be advantageous for maximizing profits.\n",
    "\n",
    "Reference: https://www.nar.realtor/blogs/economists-outlook/seasonality-in-the-housing-market\n",
    "\n",
    "**Volatility**\n",
    "\n",
    "A note about market volatility. Since the strategy we are focused on here is buy and hold, if and when there is a housing bubble, it is best to continue to hold during this time. While having a mortgage does create a liability, history shows that during a recession or related housing bubble, the rental market is not as affected as the housing market. \n",
    "\n",
    "Reference: https://www.forbes.com/sites/forbesrealestatecouncil/2020/01/02/how-will-a-recession-affect-my-rental-properties/#a4b70b45c70f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeHo = df_LA_melt_sort[df_LA_melt_sort['RegionName'] == 90046]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeHo.index = WeHo['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['RegionName','City','State','Metro','CountyName','time']\n",
    "WeHo = WeHo.drop(to_drop, axis=1)\n",
    "WeHo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plug the optimal parameter values into a new SARIMAX model\n",
    "SARIMAX_WeHo = sm.tsa.statespace.SARIMAX(WeHo, \n",
    "                                        order=(1, 1, 1), \n",
    "                                        seasonal_order=(0, 0, 1, 12), \n",
    "                                        enforce_stationarity=False, \n",
    "                                        enforce_invertibility=False)\n",
    "\n",
    "# Fit the model and print results\n",
    "output = SARIMAX_WeHo.fit()\n",
    "\n",
    "print(output.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.plot_diagnostics(figsize=(16,10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions starting from 01-01-1998 and calculate confidence intervals\n",
    "pred = output.get_prediction(start=pd.to_datetime('2016-01-01'), dynamic=False)\n",
    "pred_conf = pred.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot real vs predicted values along with confidence interval\n",
    "\n",
    "rcParams['figure.figsize'] = 15, 6\n",
    "\n",
    "# Plot observed values\n",
    "ax = WeHo['1996':].plot(label='observed')\n",
    "\n",
    "# Plot predicted values\n",
    "pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=0.9)\n",
    "\n",
    "# Plot the range for confidence intervals\n",
    "ax.fill_between(pred_conf.index,\n",
    "                pred_conf.iloc[:, 0],\n",
    "                pred_conf.iloc[:, 1], color='g', alpha=0.5)\n",
    "\n",
    "# Set axes labels\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Median Home Sale Prices (USD)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# # Get the real and predicted values\n",
    "WeHo_forecasted = pred.predicted_mean\n",
    "WeHo_truth = WeHo['2016-01-01':]\n",
    "\n",
    "# # Compute the mean square error\n",
    "# mse = ((WeHo_forecasted - WeHo_truth) ** 2).mean()\n",
    "# print('The Mean Squared Error of our forecasts is {}'.format(round(mse, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Get dynamic predictions with confidence intervals as above \n",
    "pred_dynamic = output.get_prediction(start=pd.to_datetime('2016-01-01'), dynamic=True, full_results=True)\n",
    "pred_dynamic_conf = pred_dynamic.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the dynamic forecast with confidence intervals.\n",
    "\n",
    "ax = WeHo['1996':].plot(label='observed', figsize=(20, 6))\n",
    "pred_dynamic.predicted_mean.plot(label='Dynamic Forecast', ax=ax)\n",
    "\n",
    "ax.fill_between(pred_dynamic_conf.index,\n",
    "                pred_dynamic_conf.iloc[:, 0],\n",
    "                pred_dynamic_conf.iloc[:, 1], color='g', alpha=.3)\n",
    "\n",
    "ax.fill_betweenx(ax.get_ylim(), pd.to_datetime('2016-01-01'), WeHo_forecasted.index[-1], alpha=.1, zorder=-1)\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Median Home Sale Prices (USD)')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the p, d and q parameters to take any value between 0 and 2\n",
    "p = d = q = range(0, 2)\n",
    "\n",
    "# Generate all different combinations of p, q and q triplets\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "# Generate all different combinations of seasonal p, q and q triplets\n",
    "pdqs = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a grid with pdq and seasonal pdq parameters calculated above and get the best AIC value\n",
    "ans = []\n",
    "for comb in pdq:\n",
    "    for combs in pdqs:\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(WeHo,\n",
    "                                            order=comb,\n",
    "                                            seasonal_order=combs,\n",
    "                                            enforce_stationarity=False,\n",
    "                                            enforce_invertibility=False)\n",
    "\n",
    "            output = mod.fit()\n",
    "            ans.append([comb, combs, output.bic])\n",
    "            print('SARIMAX {} x {}12 : BIC Calculated ={}'.format(comb, combs, output.bic))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the parameters with minimal AIC value\n",
    "ans_df = pd.DataFrame(ans, columns=['pdq', 'pdqs', 'bic'])\n",
    "ans_df.loc[ans_df['bic'].idxmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Interpreting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
